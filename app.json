{
  "_comment": "This file is generated. Please edit .homeycompose/app.json instead.",
  "id": "com.ollama",
  "version": "1.0.4",
  "compatibility": ">=5.0.0",
  "sdk": 3,
  "brandColor": "#000000",
  "homeyCommunityTopicId": 143768,
  "source": "https://github.com/smarthomesven/homey-ollama",
  "platforms": [
    "local"
  ],
  "name": {
    "en": "Ollama"
  },
  "description": {
    "en": "Use Local LLMs in your Flows"
  },
  "category": [
    "internet"
  ],
  "permissions": [],
  "images": {
    "small": "/assets/images/small.png",
    "large": "/assets/images/large.png",
    "xlarge": "/assets/images/xlarge.png"
  },
  "author": {
    "name": "Sven",
    "email": "sven@dypodex.com"
  },
  "bugs": {
    "url": "https://github.com/smarthomesven/homey-ollama/issues"
  },
  "flow": {
    "actions": [
      {
        "title": {
          "en": "Generate response from Ollama using model ... and prompt ..."
        },
        "titleFormatted": {
          "en": "Generate response from Ollama using model [[model]] and prompt [[prompt]]"
        },
        "tokens": [
          {
            "name": "response",
            "type": "string",
            "title": {
              "en": "Response"
            },
            "example": {
              "en": "Response from Ollama"
            }
          }
        ],
        "args": [
          {
            "type": "autocomplete",
            "name": "model",
            "title": {
              "en": "Model"
            },
            "placeholder": {
              "en": "gpt-oss:20b"
            }
          },
          {
            "type": "text",
            "name": "prompt",
            "title": {
              "en": "Prompt"
            },
            "placeholder": {
              "en": "Hello, Ollama!"
            }
          }
        ],
        "id": "generate_response"
      },
      {
        "title": {
          "en": "Generate response from Ollama using model ... and prompt ... with image ..."
        },
        "titleFormatted": {
          "en": "Generate response from Ollama using model [[model]] and prompt [[prompt]] with image [[droptoken]]"
        },
        "droptoken": [
          "image"
        ],
        "tokens": [
          {
            "name": "response",
            "type": "string",
            "title": {
              "en": "Response"
            },
            "example": {
              "en": "Response from Ollama"
            }
          }
        ],
        "args": [
          {
            "type": "autocomplete",
            "name": "model",
            "title": {
              "en": "Model"
            },
            "placeholder": {
              "en": "qwen2.5vl:3b"
            }
          },
          {
            "type": "text",
            "name": "prompt",
            "title": {
              "en": "Prompt"
            },
            "placeholder": {
              "en": "Hello, Ollama!"
            }
          }
        ],
        "id": "generate_response_image"
      },
      {
        "title": {
          "en": "Set system prompt to ..."
        },
        "titleFormatted": {
          "en": "Set system prompt to [[sysprompt]]"
        },
        "args": [
          {
            "type": "text",
            "name": "sysprompt",
            "title": {
              "en": "System prompt"
            }
          }
        ],
        "id": "set_system_prompt"
      }
    ]
  }
}